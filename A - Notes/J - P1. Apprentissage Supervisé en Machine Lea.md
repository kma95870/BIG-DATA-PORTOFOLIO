#  Apprentissage Supervis√© en Machine Learning

---

## üîπ 1. Introduction

Le **Machine Learning supervis√©** est une m√©thode o√π l‚Äôon entra√Æne un mod√®le √† partir de **donn√©es √©tiquet√©es** :

* **X** : variables explicatives (features)
* **y** : variable cible (label)

Objectif ‚Üí apprendre une fonction $f : X \to y$ capable de **g√©n√©raliser** sur de nouvelles donn√©es.

### Types de probl√®mes

* **Classification** ‚Üí pr√©dire une **cat√©gorie** (spam / non spam).
* **R√©gression** ‚Üí pr√©dire une **valeur continue** (prix d‚Äôune maison).

---

## üîπ 2. Pipeline d‚Äôun projet supervis√©

1. **Pr√©paration des donn√©es** (nettoyage, encodage, normalisation).
2. **Split Train/Test** (souvent 70/30).
3. **Choix du mod√®le** (logistique, arbre, RF, etc.).
4. **Entra√Ænement (`fit`)** ‚Üí souvent via **descente de gradient**.
5. **√âvaluation** (m√©triques adapt√©es).
6. **Optimisation** (hyperparam√®tres, r√©gularisation).
7. **D√©ploiement** (API, dashboard, batch).

---

## üîπ 3. M√©triques d‚Äô√©valuation

* Le but d‚Äôun mod√®le n‚Äôest **pas seulement d‚Äôapprendre les donn√©es d‚Äôentra√Ænement**, mais de **g√©n√©raliser**.
* Pour mesurer cette capacit√©, on compare :

  * Les **pr√©dictions** du mod√®le ($\hat{y}$)
  * Aux **valeurs r√©elles** ($y$)

üëâ Les m√©triques servent donc √† **quantifier la qualit√©** des pr√©dictions.

### üìä Classification

### Matrice de Confusion

La **base de toutes les m√©triques de classification**.

| R√©alit√© ‚Üì / Pr√©diction ‚Üí | Positif (1)       | N√©gatif (0)       |
| ------------------------ | ----------------- | ----------------- |
| **Positif (1)**          | TP (Vrai Positif) | FN (Faux N√©gatif) |
| **N√©gatif (0)**          | FP (Faux Positif) | TN (Vrai N√©gatif) |

* **TP** : le mod√®le pr√©dit 1 et c‚Äôest bien 1.
* **TN** : le mod√®le pr√©dit 0 et c‚Äôest bien 0.
* **FP** : le mod√®le pr√©dit 1 alors que c‚Äô√©tait 0 (**fausse alerte**).
* **FN** : le mod√®le pr√©dit 0 alors que c‚Äô√©tait 1 (**rat√©**).

---

### Accuracy (Exactitude) : proportion correcte

**Formule :**

$$
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
$$

**Exemple :**

* Sur 100 mails, le mod√®le en classe 90 correctement ‚Üí Accuracy = 90%.

**Cas d‚Äôutilisation :**

* OK si les classes sont **√©quilibr√©es**.
* Mauvais si les classes sont **d√©s√©quilibr√©es** (ex : 99% non-fraude ‚Üí accuracy de 99% m√™me si aucune fraude d√©tect√©e).

---

### Pr√©cision : parmi les positifs pr√©dits, combien sont vrais.

**Formule :**

$$
Pr√©cision = \frac{TP}{TP + FP}
$$

**Exemple :**

* Le mod√®le pr√©dit 20 spams, dont 15 corrects ‚Üí pr√©cision = 15/20 = **0.75**.

**Cas d‚Äôutilisation :**

* Quand **le co√ªt d‚Äôun faux positif est √©lev√©**.
  Ex : filtrage d‚Äôemails (ne pas marquer un email important comme spam).

---

### Rappel (Recall ou Sensibilit√©) : parmi les vrais positifs, combien d√©tect√©s.

**Formule :**

$$
Recall = \frac{TP}{TP + FN}
$$

**Exemple :**

* Sur 30 vrais spams, le mod√®le en d√©tecte 25 ‚Üí recall = 25/30 = **0.83**.

**Cas d‚Äôutilisation :**

* Quand **le co√ªt d‚Äôun faux n√©gatif est √©lev√©**.
  Ex : d√©tection de cancer (mieux vaut alerter trop que de rater un vrai malade).

---

### F1-score : compromis Pr√©cision/Recall.

**Formule :**

$$
F1 = 2 \cdot \frac{Pr√©cision \cdot Recall}{Pr√©cision + Recall}
$$

**Exemple :**

* Pr√©cision = 0.75, Recall = 0.83

$$
F1 = 2 \cdot \frac{0.75 \cdot 0.83}{0.75 + 0.83} \approx 0.79
$$

**Cas d‚Äôutilisation :**

* Quand il faut un **√©quilibre entre pr√©cision et rappel**.
* Exemple : d√©tection de fraude (√©viter de rater une fraude mais sans trop d‚Äôalertes inutiles).

---

### AUC-ROC (Area Under the Curve ‚Äì Receiver Operating Characteristic) : performance globale, ind√©pendamment du seuil.

* La courbe ROC trace :

  * Axe X : Taux de Faux Positifs (FPR) = $\frac{FP}{FP+TN}$
  * Axe Y : Taux de Vrais Positifs (TPR = Recall)

* L‚Äô**AUC** est l‚Äôaire sous la courbe :

  * **1.0 = parfait**
  * **0.5 = al√©atoire**

**Cas d‚Äôutilisation :**

* Pour comparer des mod√®les ind√©pendamment d‚Äôun seuil de d√©cision.
* Tr√®s utilis√© en **finance** et **m√©dical**.

---

### Balanced Accuracy : moyenne des recalls, utile en d√©s√©quilibre de classes.

**Formule :**

$$
Balanced\ Accuracy = \frac{Recall_{classe\ 1} + Recall_{classe\ 0}}{2}
$$

**Cas d‚Äôutilisation :**

* Quand les classes sont **tr√®s d√©s√©quilibr√©es**.

---

### üìà R√©gression

#### Erreur Quadratique Moyenne (MSE)

**Formule :**

$$
MSE = \frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2
$$

* Amplifie les grandes erreurs (car au carr√©).

**Exemple :**

* Vrai prix : \[100, 200], Pr√©dit : \[110, 220]

$$
MSE = \frac{(100-110)^2 + (200-220)^2}{2} = \frac{100 + 400}{2} = 250
$$

**Cas d‚Äôutilisation :**

* Quand les grosses erreurs doivent √™tre fortement p√©nalis√©es.

---

#### RMSE (Root Mean Squared Error)

**Formule :**

$$
RMSE = \sqrt{MSE}
$$

* M√™me unit√© que la variable cible.
* Plus interpr√©table que le MSE.

**Exemple (suite) :**

$$
RMSE = \sqrt{250} \approx 15.8
$$

---

#### MAE (Mean Absolute Error) : erreur absolue moyenne (robuste aux outliers).

**Formule :**

$$
MAE = \frac{1}{n}\sum_{i=1}^n |y_i - \hat{y}_i|
$$

**Exemple :**

* Vrai prix : \[100, 200], Pr√©dit : \[110, 220]

$$
MAE = \frac{|100-110| + |200-220|}{2} = \frac{10 + 20}{2} = 15
$$

**Cas d‚Äôutilisation :**

* Plus robuste aux valeurs aberrantes (outliers) que le MSE/RMSE.

---

#### R¬≤ (Coefficient de D√©termination) : proportion de variance expliqu√©e.

**Formule :**

$$
R^2 = 1 - \frac{\sum (y_i - \hat{y}_i)^2}{\sum (y_i - \bar{y})^2}
$$

* Varie entre :

  * **1** : pr√©diction parfaite
  * **0** : mod√®le aussi mauvais que la moyenne
  * **< 0** : pire que pr√©dire la moyenne !

**Cas d‚Äôutilisation :**

* Mesure la proportion de variance expliqu√©e par le mod√®le.

---

## üîπ 4. Cas d‚Äôusage et choix des m√©triques

* **D√©tection de fraude** :

  * ‚ö†Ô∏è Peu de fraudes ‚Üí classes d√©s√©quilibr√©es
  * ‚Üí Utiliser **Recall, F1, AUC-ROC**

* **Filtrage de spam** :

  * ‚ö†Ô∏è Ne pas bloquer de vrais emails ‚Üí faux positifs co√ªteux
  * ‚Üí Utiliser **Pr√©cision, F1**

* **Pr√©diction de prix immobilier** :

  * ‚ö†Ô∏è Valeurs aberrantes (maisons de luxe)
  * ‚Üí Utiliser **MAE** si robustesse souhait√©e, sinon **RMSE**

* **Sant√© (cancer, maladies)** :

  * ‚ö†Ô∏è Rater un malade est grave
  * ‚Üí Utiliser **Recall**, puis ajuster avec **F1**

---

‚úÖ **Conclusion :**
Les m√©triques ne sont pas universelles ‚Üí **elles d√©pendent du contexte m√©tier**.
Il est souvent utile de **combiner plusieurs m√©triques** pour bien juger un mod√®le.

---

## üîπ 4. Descente de Gradient

La **descente de gradient** est la m√©thode d‚Äôoptimisation la plus utilis√©e.

### √âtapes :

1. D√©finir une **fonction de co√ªt** (ex. MSE, log-loss).
2. Calculer le **gradient** (d√©riv√©e de la loss par rapport aux poids).
3. Mettre √† jour les poids :

   $$
   \theta \leftarrow \theta - \eta \cdot \nabla J(\theta)
   $$

   * $\eta$ = learning rate.

### Variantes :

* **Batch GD** : tout le dataset.
* **Stochastic GD (SGD)** : un √©chantillon √† la fois.
* **Mini-batch GD** : compromis.

### O√π est-elle utilis√©e ?

* Impl√©ment√©e automatiquement dans :

  * R√©gression logistique (`solver="saga"`, `lbfgs`‚Ä¶)
  * SVM (solveurs internes)
  * Gradient Boosting (le "gradient" vient de l√† !)
  * R√©seaux de neurones (`solver="sgd"`, `adam`)

‚ö†Ô∏è Pas utilis√©e dans kNN, Arbres de d√©cision, Random Forest.

---

## üîπ 5. Algorithmes Supervis√©s

### üìå R√©gression Lin√©aire

* **Principe** : relation lin√©aire entre X et y.
* **Formule** : $y = \beta_0 + \beta_1 x_1 + ‚Ä¶ + \epsilon$.
* **Param√®tres** : `fit_intercept`, `positive`, `n_jobs`.
* **M√©triques** : MSE, RMSE, R¬≤.
* **Cas d‚Äôusage** : pr√©vision de prix.

```python
from sklearn.linear_model import LinearRegression

model = LinearRegression(
    fit_intercept=True, #ajoute une constante. Si False, l‚Äô√©quation passe par l‚Äôorigine.
    copy_X=True, #copie X avant fit (utile pour ne pas modifier les donn√©es).
    n_jobs=None, #parall√©lisation (None ‚Üí 1 c≈ìur, -1 ‚Üí tous les c≈ìurs).
    positive=False #force les coefficients √† √™tre positifs (utile en √©conomie ou physique).
)
```

---

### üìå R√©gression Logistique

* **Principe** : classification binaire via sigmo√Øde.
* **Formule** :

  $$
  P(y=1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta X)}}
  $$
* **Param√®tres** : `penalty`, `C`, `solver`, `max_iter`.
* **M√©triques** : Accuracy, Pr√©cision, Recall, F1, AUC.
* **Cas d‚Äôusage** : d√©tection fraude, diagnostic m√©dical.

```python
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(
    penalty='l2', #r√©gularisation : "l1", "l2", "elasticnet", "none".
    dual=False, #formulation duale (rare, utile si nb_features > nb_samples).
    tol=1e-4, #tol√©rance d‚Äôarr√™t pour l‚Äôoptimisation.
    C=1.0, #inverse de la r√©gularisation (petit C = forte r√©gularisation).
    fit_intercept=True, #ajoute le biais.
    intercept_scaling=1, #utile avec solver "liblinear".
    class_weight=None, #pond√©ration des classes (utile si d√©s√©quilibr√©es).
    random_state=None, #reproductibilit√©.
    solver='lbfgs', #algorithme : "newton-cg", "lbfgs", "liblinear", "sag", "saga".
    max_iter=100, #it√©rations max.
    multi_class='auto', #"auto", "ovr" (un contre tous), "multinomial".
    verbose=0, #niveau de logs.
    warm_start=False, #garde les coefficients d‚Äôun pr√©c√©dent fit.
    n_jobs=None, #parall√©lisation (seulement pour liblinear).
    l1_ratio=None #uniquement si penalty="elasticnet".
)
```

---

### üìå k-Nearest Neighbors (kNN)

* **Principe** : un point est class√© selon les k plus proches voisins.
* **Param√®tres** : `n_neighbors`, `weights`, `p`, `metric`.
* **M√©triques** : Accuracy, F1 (classif), MAE (r√©gr.).
* **Cas d‚Äôusage** : reconnaissance de formes, recommandation.

```python
from sklearn.neighbors import KNeighborsClassifier

model = KNeighborsClassifier(
    n_neighbors=5, #nombre de voisins k.
    weights='uniform', #"uniform" (√©gaux) ou "distance" (pond√©r√©s).
    algorithm='auto', #"auto", "ball_tree", "kd_tree", "brute".
    leaf_size=30, #taille des feuilles (optimisation KDTree/BallTree).
    p=2, #puissance ‚Üí p=1 (Manhattan), p=2 (Euclidean).
    metric='minkowski', #distance ‚Üí "minkowski", "manhattan", "euclidean", etc.
    metric_params=None, #param√®tres suppl√©mentaires pour metric custom.
    n_jobs=None #parall√©lisation.
)
```


---

### üìå Arbres de D√©cision

* **Principe** : r√®gles successives (if/else) via entropie ou Gini.
* **Param√®tres** : `criterion`, `max_depth`, `min_samples_split`.
* **M√©triques** : Accuracy, F1, MSE.
* **Cas d‚Äôusage** : segmentation clients, scoring risque.

```python
from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier(
    criterion='gini', # mesure d‚Äôimpuret√© ("gini", "entropy", "log_loss").
    splitter='best', # "best" ou "random".
    max_depth=None, # profondeur max.
    min_samples_split=2, # nb min pour split.
    min_samples_leaf=1, # nb min dans une feuille.
    min_weight_fraction_leaf=0.0, # proportion min du poids total.
    max_features=None, # nb max de features √† tester par split.
    random_state=None, 
    max_leaf_nodes=None, # limite du nb de feuilles.
    min_impurity_decrease=0.0, # seuil d‚Äôimpuret√© pour split.
    class_weight=None, # "balanced" ou dict.
    ccp_alpha=0.0 # √©lagage via complexit√©.
)
```

---

### üìå Random Forest

* **Principe** : ensemble de plusieurs arbres ‚Üí vote/moyenne.
* **Param√®tres** : `n_estimators`, `max_features`, `bootstrap`, `oob_score`.
* **M√©triques** : Accuracy, F1, MSE, R¬≤.
* **Cas d‚Äôusage** : baseline robuste sur donn√©es tabulaires.

```python
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(
    n_estimators=100, # nb d‚Äôarbres.
    criterion='gini', # crit√®re d‚Äôimpuret√©.
    max_depth=None, # comme arbre.
    min_samples_split=2, # comme arbre.
    min_samples_leaf=1, # comme arbre.
    min_weight_fraction_leaf=0.0, 
    max_features='sqrt', 
    max_leaf_nodes=None, 
    min_impurity_decrease=0.0, 
    bootstrap=True, # √©chantillonnage avec remise.
    oob_score=False, # calcule score out-of-bag.
    n_jobs=None, 
    random_state=None, 
    verbose=0, 
    warm_start=False, # ajoute des arbres sans r√©entra√Æner tout.
    class_weight=None, # pond√©ration des classes.
    ccp_alpha=0.0, # √©lagage.
    max_samples=None # nb d‚Äô√©chantillons tir√©s si bootstrap=True.
)
```
---

### üìå Gradient Boosting

* **Principe** : arbres s√©quentiels corrigeant les erreurs des pr√©c√©dents.
* **Param√®tres** : `loss`, `learning_rate`, `n_estimators`, `subsample`.
* **M√©triques** : AUC (classif), RMSE (r√©gr.).
* **Cas d‚Äôusage** : Kaggle, donn√©es structur√©es complexes.

```python
from sklearn.ensemble import GradientBoostingClassifier

model = GradientBoostingClassifier(
    loss='log_loss', #fonction de perte ‚Üí "log_loss", "exponential".
    learning_rate=0.1, #vitesse d‚Äôapprentissage (plus petit ‚Üí plus lent mais plus pr√©cis).
    n_estimators=100, #nb d‚Äôarbres.
    subsample=1.0, #fraction d‚Äô√©chantillons utilis√©s √† chaque it√©ration.
    criterion='friedman_mse', #mesure d‚Äôimpuret√©.
    min_samples_split=2, 
    min_samples_leaf=1, 
    min_weight_fraction_leaf=0.0, 
    max_depth=3, 
    min_impurity_decrease=0.0, 
    init=None, #mod√®le initial.
    random_state=None, 
    max_features=None, 
    verbose=0, 
    max_leaf_nodes=None, 
    warm_start=False, 
    validation_fraction=0.1, #proportion utilis√©e pour early stopping.
    n_iter_no_change=None, #early stopping si pas d‚Äôam√©lioration
    tol=1e-4, 
    ccp_alpha=0.0 
)
```

---

### üìå Support Vector Machines (SVM)

* **Principe** : s√©parer les classes par un hyperplan √† marge max.
* **Param√®tres** : `C`, `kernel`, `gamma`, `degree`.
* **M√©triques** : Accuracy, F1, AUC.
* **Cas d‚Äôusage** : bioinformatique, reconnaissance faciale.

```python
from sklearn.svm import SVC

model = SVC(
    C=1.0, # r√©gularisation (petit C ‚Üí marge plus large).
    kernel='rbf', # "linear", "poly", "rbf", "sigmoid".
    degree=3, # degr√© polyn√¥me (si poly).
    gamma='scale', # "scale", "auto", float.
    coef0=0.0, # param√®tre ind√©pendant (poly/sigmoid).
    shrinking=True, # heuristique pour acc√©l√©rer.
    probability=False, # calcule des probabilit√©s (lent).
    tol=1e-3, #
    cache_size=200, # m√©moire cache (MB).
    class_weight=None, # pond√©ration.
    verbose=False, #
    max_iter=-1, # -1 = infini.
    decision_function_shape='ovr', #
    break_ties=False, # "ovr" ou "ovo".
    random_state=None # gestion d‚Äô√©galit√©.
)
```

---

### üìå R√©seaux de Neurones (MLP)

* **Principe** : couches de neurones reli√©s par des poids, entra√Æn√©s via backpropagation + gradient descent.
* **Param√®tres** : `hidden_layer_sizes`, `activation`, `solver`, `alpha`, `learning_rate`.
* **M√©triques** : Accuracy, F1 (classif), MSE, R¬≤ (r√©gr.).
* **Cas d‚Äôusage** : donn√©es non lin√©aires, vision, NLP.

---

## üîπ 6. Hyperparam√®tres ‚Äì Fiche Synth√®se

| Algorithme            | Param√®tres cl√©s                                       | Impact                                            |
| --------------------- | ----------------------------------------------------- | ------------------------------------------------- |
| R√©gression Lin√©aire   | `fit_intercept`, `positive`                           | Ajuste le biais, contrainte de signe              |
| R√©gression Logistique | `penalty`, `C`, `solver`, `max_iter`                  | R√©gularisation, optimisation                      |
| kNN                   | `n_neighbors`, `weights`, `p`                         | Nb de voisins, pond√©ration, distance              |
| D√©cision Tree         | `criterion`, `max_depth`, `min_samples_split`         | Qualit√© split, profondeur, taille                 |
| Random Forest         | `n_estimators`, `max_features`, `bootstrap`           | Nb arbres, diversit√©, √©chantillonnage             |
| Gradient Boosting     | `learning_rate`, `n_estimators`, `subsample`          | Vitesse, nb d‚Äôarbres, sous-√©chantillonnage        |
| SVM                   | `C`, `kernel`, `gamma`, `degree`                      | R√©gularisation, type noyau, influence locale      |
| R√©seaux de Neurones   | `hidden_layer_sizes`, `activation`, `solver`, `alpha` | Architecture, fonction d‚Äôactivation, optimisation |

---

## ‚úÖ Conclusion

* L‚Äôapprentissage supervis√© repose sur :

  1. Des **donn√©es √©tiquet√©es**.
  2. Des **mod√®les adapt√©s** (lin√©aires, arbres, for√™ts, r√©seaux‚Ä¶).
  3. Une **optimisation via descente de gradient** (selon l‚Äôalgo).
  4. Une **√©valuation par m√©triques** adapt√©es au contexte m√©tier.

üëâ Choisir le bon algorithme d√©pend de la **nature des donn√©es**, du **volume**, et de la **m√©trique business** √† optimiser.

---