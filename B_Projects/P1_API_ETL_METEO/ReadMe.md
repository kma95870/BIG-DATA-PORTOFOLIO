# ğŸŒ¦ï¸ Open-Meteo ETL â€” Pipeline mÃ©tÃ©o automatisÃ© avec Docker, PostgreSQL & Streamlit

---

## ğŸ§  **Objectif du projet**

Ce projet met en place un **pipeline ETL complet** permettant de :

1. **Ingest** â†’ RÃ©cupÃ©rer les donnÃ©es mÃ©tÃ©o depuis lâ€™API **Open-Meteo**.
2. **Transform** â†’ Nettoyer, structurer et stocker les donnÃ©es en **Parquet**.
3. **Load** â†’ Charger ces donnÃ©es dans une base **PostgreSQL** (via Docker).
4. **Visualiser** â†’ Afficher les rÃ©sultats dans un **dashboard Streamlit** interactif.

Ce projet dÃ©montre une architecture de donnÃ©es moderne, conteneurisÃ©e et automatisÃ©e â€” prÃªte Ã  Ãªtre Ã©tendue vers le cloud.

---

## ğŸ§© **Architecture**

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ingest.py          â”‚  â†’ Appel API Open-Meteo (JSON)
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ transform.py       â”‚  â†’ Nettoyage + format Parquet
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ load.py            â”‚  â†’ Chargement dans PostgreSQL
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ PostgreSQL (Docker)â”‚  â†’ Tables weather_hourly & weather_daily
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Streamlit Dashboardâ”‚  â†’ Visualisation des donnÃ©es mÃ©tÃ©o
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ **Technologies**

| Composant        | RÃ´le                          | Outil                                 |
| ---------------- | ----------------------------- | ------------------------------------- |
| Source           | API de donnÃ©es mÃ©tÃ©o          | [Open-Meteo](https://open-meteo.com/) |
| Extraction       | Appel API + JSON              | `requests`                            |
| Transformation   | Structuration & nettoyage     | `pandas`, `pyarrow`                   |
| Chargement       | Base de donnÃ©es relationnelle | `PostgreSQL` via Docker               |
| Visualisation    | Dashboard interactif          | `Streamlit`                           |
| Conteneurisation | Environnement reproductible   | `Docker Compose`                      |

---

## ğŸ§± **Structure du projet**

```
P1_API_ETL_METEO/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest.py              # Appel API Open-Meteo
â”‚   â”œâ”€â”€ transform.py           # Nettoyage + Parquet
â”‚   â””â”€â”€ load.py                # Chargement PostgreSQL
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # DonnÃ©es brutes (JSON)
â”‚   â””â”€â”€ processed/             # DonnÃ©es nettoyÃ©es (Parquet)
â”œâ”€â”€ app.py                     # Dashboard Streamlit
â”œâ”€â”€ docker-compose.yml         # Stack Docker (Postgres + Adminer + Streamlit)
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â””â”€â”€ README.md
```

---

## ğŸš€ **Installation & Lancement**

### 1ï¸âƒ£ Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/tonprofil/BIG-DATA-PORTOFOLIO.git
cd B_Projects/P1_API_ETL_METEO
```

### 2ï¸âƒ£ Lancer les conteneurs Docker

```bash
docker compose up -d
```

âœ… Cela dÃ©marre :

* **PostgreSQL** â†’ base de donnÃ©es `etl_db` (port `5433`)
* **Adminer** â†’ interface web SQL (port `8080`)
* **Streamlit** â†’ dashboard mÃ©tÃ©o (port `8501`)

---

### 3ï¸âƒ£ VÃ©rifier les services

| Service       | URL                                            | Description                   |
| ------------- | ---------------------------------------------- | ----------------------------- |
| **Adminer**   | [http://localhost:8080](http://localhost:8080) | Interface SQL pour PostgreSQL |
| **Streamlit** | [http://localhost:8501](http://localhost:8501) | Dashboard mÃ©tÃ©o interactif    |

---

## ğŸ§® **ExÃ©cution manuelle du pipeline**

Tu peux exÃ©cuter les Ã©tapes individuellement depuis le terminal :

```bash
python scripts/ingest.py      # 1ï¸âƒ£ RÃ©cupÃ©ration API Open-Meteo
python scripts/transform.py   # 2ï¸âƒ£ Transformation en Parquet
python scripts/load.py        # 3ï¸âƒ£ Chargement dans PostgreSQL
```

Les fichiers produits seront visibles ici :

```
data/raw/20251017/openmeteo_20251017TxxxxxxZ.json
data/processed/hourly.parquet
data/processed/daily.parquet
```

---

## ğŸ“Š **Visualisation avec Streamlit**

Le dashboard affiche :

* Les derniÃ¨res tempÃ©ratures min / max ğŸŒ¡ï¸
* Les prÃ©cipitations journaliÃ¨res ğŸŒ§ï¸
* Le vent horaire ğŸ’¨
* Des statistiques rÃ©sumÃ©es sur la pÃ©riode collectÃ©e ğŸ“ˆ

### Lancement manuel :

```bash
streamlit run app.py
```

Puis ouvrir : [http://localhost:8501](http://localhost:8501)

---

## ğŸ—„ï¸ **Connexion Ã  PostgreSQL**

* **Host** : `localhost`
* **Port** : `5433`
* **Database** : `etl_db`
* **User** : `postgres`
* **Password** : `postgres`

Tu peux te connecter via :
ğŸ‘‰ **Adminer** (interface web)
ou
ğŸ‘‰ **psql / DBeaver / Python (SQLAlchemy)**

---

## ğŸ§  **AmÃ©liorations futures**

* Ajout de lâ€™orchestration automatique (Airflow).
* Ajout dâ€™un contrÃ´le qualitÃ© des donnÃ©es (vÃ©rifications dâ€™intÃ©gritÃ©).
* Extension multi-villes (Paris, Lyon, Berlin...).
* DÃ©ploiement du pipeline sur le Cloud (AWS ou GCP).
* IntÃ©gration dâ€™un cache API ou dâ€™un mode incrÃ©mental.

---

## âš ï¸ **ProblÃ¨mes rencontrÃ©s & solutions**

| ğŸ’¥ ProblÃ¨me                                                             | ğŸ” Cause                                              | ğŸ§© Solution                                                         |
| ----------------------------------------------------------------------- | ----------------------------------------------------- | ------------------------------------------------------------------- |
| `requests.exceptions.Timeout` lors de lâ€™appel API                       | Lâ€™API Open-Meteo met parfois trop de temps Ã  rÃ©pondre | Ajout dâ€™un `timeout=30` dans `requests.get()`                       |
| Erreur `"AttributeError: 'DatetimeIndex' object has no attribute 'dt'"` | Mauvaise conversion dans `pd.to_datetime()`           | CorrigÃ© avec `.to_series().dt.date`                                 |
| Connexion SQLAlchemy impossible                                         | Mauvais port ou container Postgres non dÃ©marrÃ©        | VÃ©rification avec `docker ps` + port `5433`                         |
| Erreur `OperationalError` sur PostgreSQL                                | Docker Postgres pas encore prÃªt                       | Attendre quelques secondes ou relancer `docker compose up -d`       |
| Images manquantes sur GitHub                                            | Mauvais chemin relatif dans le README                 | Corriger avec `![texte](images/nom_image.png)` ou dossier `/assets` |

---

## ğŸ“š **Exemple de rÃ©sultats**

| date       | tmin_c | tmax_c | precip_sum_mm |
| ---------- | -----: | -----: | ------------: |
| 2025-10-17 |    9.2 |   18.6 |           0.0 |
| 2025-10-18 |   11.1 |   20.2 |           1.4 |
| 2025-10-19 |   10.8 |   19.7 |           2.3 |

---

## ğŸ‘¨â€ğŸ’» **Auteur**

**Moha Krim**
ğŸ“Š Data Engineer / Analyst â€” PassionnÃ© de Big Data & Cloud
ğŸ“« [LinkedIn](https://www.linkedin.com/in/mohamed-amine-krim-65bb09220/) Â· [GitHub](https://github.com/kma95870)

---
